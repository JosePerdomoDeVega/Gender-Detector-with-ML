{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca01c56b960d0616",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Gender Detector using images\n",
    "\n",
    "--> Let´s do the following steps:\n",
    "- Put the images of the people you want to scan in the \"User-Images-For-Detection\" directory (make sure that your photos are in jpg format, there is only one face in each photo and the name of each file is the name of the person in the picture)\n",
    "- Train a Logistic Regression Model and a Perceptron with a thousand photos of famous people, rate them as woman or man, we will observe the accuracy of each model and select the better one.\n",
    "- The images must pass 2 layers of processing: Number one, *face recognition* (Each image will be trim, it only shows the face of the image). Number two, *face transformed into a characteristic vector (embedding)* (Every photo will convert into a vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922c5a4aeebcf9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Training models, testing them and select the best.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea479179269e0e15",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T23:46:50.270570100Z",
     "start_time": "2024-07-01T23:46:50.043621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 89.68%\n",
      "Perceptron score: 82.67%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "import os\n",
    "import glob\n",
    "\n",
    "df_train = pd.read_csv('Images-CelebA-1K//train_df_vectors.csv')\n",
    "df_test = pd.read_csv('Images-CelebA-1K//test_df_vectors.csv')\n",
    "\n",
    "X_train = df_train.iloc[:, 2:].values\n",
    "y_train = df_train.iloc[:, 1].values\n",
    "X_test = df_test.iloc[:, 2:].values\n",
    "y_test = df_test.iloc[:, 1].values\n",
    "\n",
    "clf_logistic_reg = LogisticRegression()\n",
    "clf_perceptron = Perceptron()\n",
    "\n",
    "\n",
    "clf_logistic_reg.fit(X_train, y_train)\n",
    "clf_perceptron.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f'Logistic Regression score: {clf_logistic_reg.score(X_test, y_test)*100:.2f}%')\n",
    "print(f'Perceptron score: {clf_perceptron.score(X_test, y_test)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce8235fa3b0ace",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**The Logistic Regression score is higher, so the model is better.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341f1b430a5cc8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-Get paths of your images (You should move them to the directory \\\"User-Images-For-Detection\\\" of the project). Also remember to rename your photos with the name of the person on the image, so you can recognize him/her in the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "481c92538d57488",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T23:51:31.891296100Z",
     "start_time": "2024-07-01T23:50:56.743312300Z"
    }
   },
   "outputs": [],
   "source": [
    "path = input(\"Write the path of your computer to the directory \\\"User-Images-For-Detection\\\" (Include the name of this directory)\\n Example: C://Users//Users//PycharmProjects//Project//User-Images-For-Detection\")\n",
    "\n",
    "pattern = os.path.join(path, '*.jpg')\n",
    "jpg_files = glob.glob(pattern)\n",
    "\n",
    "for file in jpg_files:\n",
    "    jpg_files[jpg_files.index(file)] = file.replace(\"\\\\\", \"//\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e40f66952183d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-Let´s transform your images into prediction of the model. It will return the apparent gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a8917ab9689dd4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-01T23:51:40.332141100Z",
     "start_time": "2024-07-01T23:51:33.414994800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JosePerdomo is male according to the Logistic Model.\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "\n",
    "for photo in jpg_files:\n",
    "\n",
    "    \n",
    "    embedding_objs = DeepFace.represent(img_path = photo,\n",
    "                                        model_name = 'Facenet512',\n",
    "                                        detector_backend = 'opencv',\n",
    "                                        enforce_detection=False\n",
    "                                        )\n",
    "    name = photo[photo.rfind(\"//\") + 2:photo.rfind(\".\")]\n",
    "    embedding = embedding_objs[0][\"embedding\"]\n",
    "    gender = clf_logistic_reg.predict(np.array(embedding).reshape(1, -1))\n",
    "    \n",
    "    \n",
    "    print(f'{name} is {gender[0]} according to the Machine Learning Model.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9bd058c610232",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
